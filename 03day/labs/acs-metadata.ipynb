{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure OpenAI\n",
    "\n",
    "We'll start as usual by defining our Azure OpenAI service API key and endpoint details, specifying the model deployment we want to use and then we'll initiate a connection to the Azure OpenAI service.\n",
    "\n",
    "**NOTE**: As with previous labs, we'll use the values from the `.env` file in the root of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    " # Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found OpenAPI Base Endpoint: \" + os.getenv(\"OPENAI_API_BASE\"))\n",
    "else: \n",
    "    print(\"No file .env found\")\n",
    "openai_api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "deployment_name = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "embedding_name = os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENTE\")\n",
    "acs_service_name = os.getenv(\"AZURE_SEARCH_SERVICE_NAME\")\n",
    "acs_endpoint_name = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "acs_index_name = \"gds-metadata-index-hzm\"\n",
    "acs_api_key = os.getenv(\"AZURE_SEARCH_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inititate  the Embedding model, the completion and the instrcut model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "# Create an Embeddings Instance of Azure OpenAI\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base = openai_api_base,\n",
    "    openai_api_version = openai_api_version,\n",
    "    deployment_name =\"text-embedding-ada-002\",\n",
    "    openai_api_key = openai_api_key,\n",
    "    openai_api_type = openai_api_type,\n",
    "    embedding_ctx_length=8191,\n",
    "    chunk_size=1000,\n",
    "    max_retries=6)\n",
    "\n",
    "# Create a Completion Instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base= openai_api_base,\n",
    "    openai_api_version= openai_api_version,\n",
    "    deployment_name=\"gpt-35-turbo-16k\",\n",
    "    temperature=0,\n",
    "    openai_api_key= openai_api_key,\n",
    "    openai_api_type = openai_api_type,\n",
    "    max_retries=6,\n",
    "    max_tokens=4000\n",
    ")\n",
    "\n",
    "llmi = AzureOpenAI(\n",
    "    openai_api_base= openai_api_base,\n",
    "    openai_api_version= openai_api_version,\n",
    "    deployment_name=\"gpt-35-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key= openai_api_key,\n",
    "    openai_api_type = openai_api_type,\n",
    "    max_retries=6,\n",
    "    max_tokens=4000\n",
    ")\n",
    "print('Completed creation of embedding and completion instances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data from the movies.csv file using the Langchain CSV document loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# metadata fields in CSV\n",
    "# id,SourceSysId,SourceSysName,businessLine,BusinessEntity,Maturity,DataLifecycle,Location,dataDomain,DataSubDomain,GoldenDataSetName,\n",
    "# DataExpert,DataValidator,DataDescription,data_steward_id,DataStewardID,data_owner_id,DataOwnerID,DataOwnerName,DataStewardName,\n",
    "# DataClassification,LegalGroundCollection,HistoricalData,UnlockedGDP,CIARating,NbDataElements\n",
    "\n",
    "# id,original_language,original_title,popularity,release_date,vote_average,vote_count,genre,overview,revenue,runtime,tagline\n",
    "loader = CSVLoader(file_path='../data/metadatashort.csv', source_column='GoldenDataSetName', encoding='utf-8', \n",
    "                   csv_args={'delimiter':',', \n",
    "                             'fieldnames': ['id','SourceSysId','SourceSysName','businessLine','BusinessEntity','Maturity','DataLifecycle','Location','dataDomain','DataSubDomain','GoldenDataSetName',\n",
    "                                            'DataExpert','DataValidator','DataDescription','DataStewardID','DataOwnerID','DataOwnerName','DataStewardName',\n",
    "                                            'DataClassification','LegalGroundCollection','HistoricalData','UnlockedGDP','CIARating','NbDataElements']\n",
    "                            }\n",
    "                    )\n",
    "data = loader.load()\n",
    "data = data[1:101] # reduce dataset if you want\n",
    "print('Loaded %s datasets' % len(data))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedings for every entry/row in our `data` object and put everything in an object called Items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid # The uuid library in Python is used to generate unique IDs, known as Universally Unique Identifiers (UUIDs), which can be used for objects, sessions, or transactions where uniqueness is required.\n",
    "\n",
    "# Let's take a quick look at the data structure of the CSVLoader\n",
    "print(data[0])\n",
    "print(data[0].metadata['source'])\n",
    "print(\"----------\")\n",
    "\n",
    "# Generate Document Embeddings for page_content field in the movies CSVLoader dataset using Azure OpenAI\n",
    "items = []\n",
    "for dataset in data:\n",
    "    content = dataset.page_content\n",
    "    items.append(dict([(\"id\", str(uuid.uuid4())), (\"GoldenDataSetName\", dataset.metadata['source']), (\"content\", content), (\"content_vector\", embeddings.embed_query(content))]))\n",
    "\n",
    "# Print out a sample item to validate the updated data structure.\n",
    "# It should have the id, content, and content_vector values.\n",
    "print(items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id: GDS49573\\nSourceSysId: SYSUID.617170\\nSourceSysName: Core contact repository\\nbusinessLine: Innovation & Technology\\nBusinessEntity: Masreph\\nMaturity: Catalogued for processing\\nDataLifecycle: Active (Under review)\\nLocation: Europe\\ndataDomain: IT\\nDataSubDomain: Data\\nGoldenDataSetName: Finance App Insights\\nDataExpert: Olivares, Neri\\nDataValidator: Webb, Jude\\nDataDescription: \"Finance App Insights\" is a dataset that provides valuable insights into user behavior and trends within the finance app industry.\\nDataStewardID: DOWID654616\\nDataOwnerID: DOWID339056\\nDataOwnerName: Sambula-Sheriff, Ethan\\nDataStewardName: Webb, Jason\\nDataClassification: Natural data\\nLegalGroundCollection: Provision of financial products and services\\nHistoricalData: Yes\\nUnlockedGDP: Achieved (Production)\\nCIARating: 1-1-1\\nNbDataElements: 27'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset.page_content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.embed_query(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadadata  into Azure Cognitive Search\n",
    "\n",
    "Next, we'll create the Azure Cognitive Search index, embed the loaded metdataset from the CSV file, and upload the data into the newly created index. Depending on the number of movies loaded and rate limiting, this might take a while to do the embeddings so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Create the Azure Cognitive Search Index Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(\n",
    "    acs_endpoint_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define search carachteristics for the movie's fields in the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields in the csv file\n",
    "# Definition of the structure of the index. \n",
    "# id,SourceSysId,SourceSysName,businessLine,BusinessEntity,Maturity,DataLifecycle,Location,dataDomain,DataSubDomain,GoldenDataSetName,\n",
    "# DataExpert,DataValidator,DataDescription,data_steward_id,DataStewardID,data_owner_id,DataOwnerID,DataOwnerName,DataStewardName,\n",
    "# DataClassification,LegalGroundCollection,HistoricalData,UnlockedGDP,CIARating,NbDataElements\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SimpleField(name=\"SourceSysId\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"SourceSysName\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"Maturity\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataLifecycle\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"Location\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"dataDomain\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataSubDomain\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"GoldenDataSetName\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataExpert\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataValidator\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataDescription\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"DataStewardID\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"DataOwnerID\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataOwnerName\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataStewardName\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"DataClassification\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"LegalGroundCollection\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"HistoricalData\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"UnlockedGDP\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"CIARating\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"NbDataElements\", type=SearchFieldDataType.String,sortable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Vector Search Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Semantic Configuration (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"GoldenDataSetName\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"GoldenDataSetName\"), SemanticField(field_name=\"DataDescription\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the semantic settings with the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the search index with the desired vector search and semantic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gds-metadata-index-hzm index was created.\n"
     ]
    }
   ],
   "source": [
    "# Create the search index with the desired vector search and semantic configurations\n",
    "index = SearchIndex(\n",
    "    name=acs_index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_settings=semantic_settings\n",
    ")\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f'The {result.name} index was created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload metadata to Azure Cognitive Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Insert Text and Embeddings into the Azure Cognitive Search index created.\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "result = search_client.upload_documents(items)\n",
    "print(\"Successfully added documents to Azure Cognitive Search index.\")\n",
    "print(f\"Uploaded {len(data)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's do a plain vanilla text search, no vectors or embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Finance Persona Data\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    include_total_count=True,\n",
    "    top=3\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using only text-based search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over Results\n",
    "# Index Fields - id, content, content_vector\n",
    "for result in results:\n",
    "    print(\"Dataset: {}\".format(result[\"content\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do a vector search that uses the embeddings we created and inserted into `content_vector` field in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is the data expert of Enterprise Equity Segmentation Map\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# You can see here that we are getting the embedding representation of the query.\n",
    "vector = Vector(\n",
    "    value=embeddings.embed_query(query),\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "results = list(search_client.search(\n",
    "    search_text=\"\",\n",
    "    include_total_count=True,\n",
    "    vectors=[vector],\n",
    "    select=[\"id\", \"content\", \"GoldenDataSetName\"],\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using only vector-based search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over results and print out the content.\n",
    "for result in results:\n",
    "    print(result['GoldenDataSetName'])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did that return what you expected? Probably not, let's dig deeper to see why. Let's do the same search again, but this time let's return the `search score` so we can see the value returned by the cosine similarity vector store calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try again, but this time let's add the relevance score to maybe see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is the data expert of Enterprise Equity Segmentation Map\"\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# You can see here that we are getting the embedding representation of the query.\n",
    "vector = Vector(\n",
    "    value=embeddings.embed_query(query),\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "results = list(search_client.search(\n",
    "    search_text=\"\",\n",
    "    include_total_count=True,\n",
    "    vectors=[vector],\n",
    "    select=[\"id\", \"content\", \"GoldenDataSetName\"],\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using vector search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over results and print out the id and search score.\n",
    "for result in results:  \n",
    "    print(f\"Id: {result['id']}\")\n",
    "    print(f\"Id: {result['GoldenDataSetName']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the `search score` you will see the relevant ranking of the closest vector match to the query inputted. The lower the score the farther apart the two vectors are. Let's change the search term and see if we can get a higher Search Score which means a higher match and closer vector proximity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try again, but this time let's add the relevance score to maybe see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query =  \"Who is the data expert of Enterprise Equity Segmentation Map\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# You can see here that we are getting the embedding representation of the query.\n",
    "vector = Vector(\n",
    "    value=embeddings.embed_query(query),\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "results = list(search_client.search(\n",
    "    search_text=\"\",\n",
    "    include_total_count=True,\n",
    "    vectors=[vector],\n",
    "    select=[\"id\", \"content\", \"GoldenDataSetName\"],\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using vector search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over results and print out the id and search score.\n",
    "for result in results:  \n",
    "    print(f\"Id: {result['id']}\")\n",
    "    print(f\"Id: {result['GoldenDataSetName']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(\"----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** As you have seen from the results, different inputs can return different results, it all depends on what data is in the Vector Store. The higher the score the higher the likelihood of a match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Searching using Azure Cognitive Search\n",
    "What is Hybrid Search? The search is implemented at the field level, which means you can build queries that include vector fields and searchable text fields. The queries execute in parallel and the results are merged into a single response. Optionally, add semantic search, currently in preview, for even more accuracy with L2 reranking using the same language models that power Bing.\n",
    "\n",
    "**NOTE:** Hybrid Search is a key value proposition of Azure Cognitive Search in comparison to vector only data stores. Click Hybrid Search for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "# Let's try our original query again using Hybrid Search (ie. Combination of Text & Vector Search)\n",
    "query = \"Who is the data expert of Enterprise Equity Segmentation Map?\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# You can see here that we are getting the embedding representation of the query.\n",
    "vector = Vector(\n",
    "    value=embeddings.embed_query(query),\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# Notice we also fill in the search_text parameter with the query.\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    include_total_count=True,\n",
    "    top=10,\n",
    "    vectors=[vector],\n",
    "    select=[\"id\", \"content\", \"GoldenDataSetName\"],\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using vector search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over results and print out the id and search score.\n",
    "for result in results:  \n",
    "    print(f\"Id: {result['id']}\")\n",
    "    print(result['GoldenDataSetName'])\n",
    "    print(f\"Hybrid Search Score: {result['@search.score']}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hybrid Search\n",
    "####  Let's try our more specific query again to see the difference in the score returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is the data expert of Enterprise Equity Segmentation Map?\"\n",
    "search_client = SearchClient(\n",
    "    acs_endpoint_name,\n",
    "    acs_index_name,\n",
    "    AzureKeyCredential(acs_api_key)\n",
    ")\n",
    "\n",
    "# You can see here that we are getting the embedding representation of the query.\n",
    "vector = Vector(\n",
    "    value=embeddings.embed_query(query),\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# -----\n",
    "# Notice we also fill in the search_text parameter with the query along with the vector.\n",
    "# -----\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    include_total_count=True,\n",
    "    top=10,\n",
    "    vectors=[vector],\n",
    "    select=[\"id\", \"content\", \"GoldenDataSetName\"],\n",
    "))\n",
    "\n",
    "# Print count of total results.\n",
    "print(f\"Returned {len(results)} results using hybrid search.\")\n",
    "print(\"----------\")\n",
    "# Iterate over results and print out the id and search score.\n",
    "for result in results:  \n",
    "    print(f\"Id: {result['id']}\")\n",
    "    print(f\"Title: {result['GoldenDataSetName']}\")\n",
    "    print(f\"Hybrid Search Score: {result['@search.score']}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it All Together with Retrieval Augmented Generation (RAG) + Langchain (LC)\n",
    "Now that we have our Vector Store setup and data loaded, we are now ready to implement the RAG pattern using AI Orchestration. At a high-level, the following steps are required:\n",
    "\n",
    "* Ask the question\n",
    "* Create Prompt Template with inputs\n",
    "* Get Embedding representation of inputted question\n",
    "* Use embedded version of the question to search Azure Cognitive Search (ie. The Vector Store)\n",
    "* Inject the results of the search into the Prompt Template & Execute the Prompt to get the completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question to be asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"List all Golden dataset from Business Line Leasing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template with variables, note the curly braces\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_question\",\"search_results\"],\n",
    "    template=\"\"\"\n",
    "    Question: {original_question}\n",
    "\n",
    "    Do not use any other data.\n",
    "    Only use the movie data below when responding.\n",
    "    {search_results}\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embedding for the original question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embedded=embeddings.embed_query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Vector(\n",
    "    value=question_embedded,\n",
    "    k=5,\n",
    "    fields=\"content_vector\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(search_client.search(\n",
    "    search_text=\"\",\n",
    "    include_total_count=True,\n",
    "    vectors=[vector],\n",
    "    select=[\"GoldenDataSetName\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Prompt and Execute against the Azure OpenAI to get the completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "response = chain.run({\"original_question\": question, \"search_results\": results})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `ConversationalRetrievalChain` chain   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "acs = AzureSearch(azure_search_endpoint=acs_endpoint_name,\n",
    "                 azure_search_key=acs_api_key,\n",
    "                 index_name=acs_index_name,\n",
    "                 embedding_function=embeddings.embed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initiate your retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = acs.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our  question-answering chat chain. In this case, we specify the condense question prompt, which converts the user’s question to a standalone question (using the chat history), in case the user asked a follow-up questio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt if needed\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\")\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                           retriever=acs.as_retriever(),\n",
    "                                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s ask a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"Who is the owner of the golden dataset named Trade Finance Collateral Dataset?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From where, we can also ask follow up questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"What is his data owner id?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"ok thanks, I need to do some analysis on lending practices and risk management in the finance sector, which datasets you recomend?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
